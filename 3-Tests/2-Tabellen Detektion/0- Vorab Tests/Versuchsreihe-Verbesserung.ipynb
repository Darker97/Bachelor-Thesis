{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Versuchsreihe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGFB_Etciw2u",
        "colab_type": "code",
        "outputId": "a325b9d0-283c-406f-8273-feed05f9a10f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# To determine which version you're using:\n",
        "!pip show tensorflow\n",
        "\n",
        "# For the latest nightly build:\n",
        "# !pip install tf-nightly\n",
        "# For the current version: \n",
        "#!pip install --upgrade tensorflow\n",
        "\n",
        "# For a specific version:\n",
        "#!pip install tensorflow==1.2\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.2.0rc3\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: grpcio, gast, opt-einsum, google-pasta, h5py, tensorboard, tensorflow-estimator, termcolor, wrapt, scipy, wheel, absl-py, astunparse, keras-preprocessing, six, protobuf, numpy\n",
            "Required-by: fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SemjBMnTtQee",
        "colab_type": "text"
      },
      "source": [
        "# Import\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m48sJBxtUCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import random\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from skimage.util import random_noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp00yxVM3MCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an Image with the defined Height and Width\n",
        "def createImage():\n",
        "  ArrayZiel = []\n",
        "  for y in range(0, IMG_Height):\n",
        "    tempArray = []\n",
        "    for x in range(0, IMG_Width):\n",
        "      tempArray.append(0)\n",
        "    ArrayZiel.append(np.array(tempArray))\n",
        "  return np.array(ArrayZiel)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VszsxvQJ3eEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add Noise to given Image\n",
        "def add_gaussian_noise(img):\n",
        "    mean = 0\n",
        "    var = 10\n",
        "    sigma = var ** 0.5\n",
        "    gaussian = np.random.normal(mean, sigma, (IMG_Height, IMG_Width))\n",
        "\n",
        "    noisy_image = np.zeros(img.shape, np.float32)\n",
        "\n",
        "    if len(img.shape) == 2:\n",
        "        noisy_image = img + gaussian\n",
        "    else:\n",
        "        noisy_image[:, :, 0] = img[:, :, 0] + gaussian\n",
        "        noisy_image[:, :, 1] = img[:, :, 1] + gaussian\n",
        "        noisy_image[:, :, 2] = img[:, :, 2] + gaussian\n",
        "\n",
        "    cv2.normalize(noisy_image, noisy_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
        "    noisy_image = noisy_image.astype(np.uint8)\n",
        "\n",
        "    return noisy_image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbJCp-Wb3ygN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nimmt das Image und fügt eine MehrDimensionale Tabelle ein.\n",
        "def addTabel_Mehrdimensional(image):\n",
        "  x1 = int(random.randint(0, IMG_Width-22))\n",
        "  x2 = int(random.randint(x1+20, IMG_Width-2))\n",
        "\n",
        "  y1 = int(random.randint(1, IMG_Height/2))\n",
        "  y2 = int(random.randint(y1+1, IMG_Height-2))\n",
        "\n",
        "  Tabelle = np.zeros(image.shape, np.float32)\n",
        "\n",
        "  width = x2-x1\n",
        "  height = y2-y1\n",
        "\n",
        "  AnzahlTabellen = random.randint(2,5)\n",
        "\n",
        "  # Berechne Tabelle:\n",
        "  b = int(width / AnzahlTabellen)\n",
        "\n",
        "  for x in range(x1,x2):\n",
        "    for y in range(y1, y2):\n",
        "      Temp = math.sin(((x-x1) / b) * 2 * math.pi)\n",
        "      if(Temp > 0):\n",
        "        image[y][x] = 100\n",
        "        Tabelle[y][x] = 1\n",
        "      else:\n",
        "        image[y][x] = 70\n",
        "        Tabelle[y][x] = 1\n",
        "\n",
        "  # Addieren beide Bilder zusammen\n",
        "  image = np.stack((image, image, image), axis=2)\n",
        "  Tabelle = np.stack((Tabelle, Tabelle, Tabelle), axis=2)\n",
        "\n",
        "  # image = np.resize(image, (IMG_Height, IMG_Width, 3))\n",
        "  # Tabelle = np.resize(Tabelle, (IMG_Height, IMG_Width, 3))\n",
        "\n",
        "  return image, x1, y1, x2, y2, Tabelle\n",
        "\n",
        "\n",
        "# nimmt das Image und fügt eine einDimensionale Tabelle ein.\n",
        "def addTabel_EinDimensional(image):\n",
        "  x1 = int(random.randint(0, IMG_Width-22))\n",
        "  x2 = int(random.randint(x1+20, IMG_Width-2))\n",
        "\n",
        "  width = x2-x1\n",
        "\n",
        "  Tabelle = np.zeros(image.shape, np.float32)\n",
        "\n",
        "  AnzahlTabellen = random.randint(2,5)\n",
        "\n",
        "  # Berechne Tabelle:\n",
        "  b = int(width / AnzahlTabellen)\n",
        "\n",
        "  for x in range(x1,x2):\n",
        "    y = 0\n",
        "    Temp = math.sin(((x-x1) / b) * 2 * math.pi)\n",
        "    if(Temp > 0):\n",
        "      image[y][x] = 1\n",
        "      Tabelle[y][x] = 1\n",
        "    else:\n",
        "      image[y][x] = 0\n",
        "      Tabelle[y][x] = 0\n",
        "\n",
        "  return image, x1, x2, Tabelle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsLOMOul8RLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CreateLabelData_EinDimensional(x1, x2):\n",
        "  Array = []\n",
        "\n",
        "  Array.append(x1)\n",
        "  Array.append(x2)\n",
        "  return Array\n",
        "\n",
        "\n",
        "def CreateLabelData_MehrDimensional(x1, y1, x2, y2):\n",
        "  Array = []\n",
        "\n",
        "  Array1 = []\n",
        "  Array1.append(x1)\n",
        "  Array1.append(y1)\n",
        "  Array1 = np.asarray(Array1)\n",
        "  Array.append(Array1)\n",
        "\n",
        "  Array1 = []\n",
        "  Array1.append(x2)\n",
        "  Array1.append(y2)\n",
        "  Array1 = np.asarray(Array1)\n",
        "  Array.append(Array1)\n",
        "\n",
        "  Array = np.asarray(Array)\n",
        "  return Array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFHrqrjuRbyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Baue noch einen Callback ein, damit das Training (hoffentlich) weniger Zeit in anspruch nimmt\n",
        "# Soll bei einer festgelegten Loss das Training unterbrechen\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    if logs.get('loss') < LossZumAbbruchDesTrainings:\n",
        "      print(\"\\n Low loss so cancelling the training\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovel2nVy5NCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TrainDataGenerator(AnzahlAnDaten):\n",
        "  TrainDataset = []\n",
        "  TrainLabelSet = []\n",
        "  TrainTabelSet = []\n",
        "\n",
        "  for i in range(0, AnzahlAnDaten):\n",
        "    image = createImage()\n",
        "    image = add_gaussian_noise(image)\n",
        "    image, x1,y1,x2,y2,tabel = addTabel_Mehrdimensional(image)\n",
        "    TrainTabelSet.append(tabel)\n",
        "    labelArray = CreateLabelData_EinDimensional(x1, x2)\n",
        "    TrainDataset.append(np.asarray(image))\n",
        "    TrainLabelSet.append(np.asarray(labelArray))\n",
        "\n",
        "  TrainDataset = np.asarray(TrainDataset, dtype=np.float32)\n",
        "  TrainLabelSet = np.asarray(TrainLabelSet, dtype=np.float32)\n",
        "  TrainTabelSet = np.asarray(TrainTabelSet, dtype=np.float32)\n",
        "\n",
        "  return TrainDataset, TrainLabelSet, TrainTabelSet\n",
        "\n",
        "def TestDataGenerator(AnzahlAnDaten):\n",
        "  TestDataSet = []\n",
        "  TestLabelSet = []\n",
        "  TestTabelSet = []\n",
        "\n",
        "  for i in range(0, AnzahlAnDaten):\n",
        "    # Erstellen der TestDaten\n",
        "    image = createImage()\n",
        "    image = add_gaussian_noise(image)\n",
        "    image, x1,y1,x2,y2,tabel = addTabel_Mehrdimensional(image)\n",
        "    labelArray = CreateLabelData_EinDimensional(x1, x2)\n",
        "    TestTabelSet.append(tabel)\n",
        "    TestDataSet.append(np.asarray(image))\n",
        "    TestLabelSet.append(np.asarray(labelArray))\n",
        "\n",
        "  TestDataSet = np.asarray(TestDataSet, dtype=np.float32)\n",
        "  TestTabelSet = np.asarray(TestTabelSet, dtype=np.float32)\n",
        "  TestLabelSet = np.asarray(TestLabelSet, dtype=np.float32)\n",
        "\n",
        "  return TestDataSet, TestTabelSet, TestLabelSet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFwfP3eatLjW",
        "colab_type": "text"
      },
      "source": [
        "# Erster Test: Ein Dimensional\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JdJMpGB5S2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variablen\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "IMG_Height = 32\n",
        "IMG_Width = 64\n",
        "\n",
        "AnzahlAnTrainDaten = 10000\n",
        "AnzahlAnTestDaten = 1000\n",
        "DropoutRate = 0.5\n",
        "\n",
        "LossZumAbbruchDesTrainings = 0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgvwjLR05T8Z",
        "colab_type": "text"
      },
      "source": [
        "## 1) Daten Erzeugen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdKP9TEKuzvw",
        "colab_type": "code",
        "outputId": "e159a5ee-a798-4548-ecd4-fc38c0d925a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        }
      },
      "source": [
        "# Bild Erzeuger\n",
        "image = createImage()\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "image = add_gaussian_noise(image)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "# add Table\n",
        "image, x1,y1,x2,y2,tabel = addTabel_Mehrdimensional(image)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(tabel)\n",
        "plt.show()\n",
        "\n",
        "print(str(x1) + '-----' + str(x2))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "41-----62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydT4CzJV8DNn",
        "colab_type": "code",
        "outputId": "d61a2e48-81e1-4286-cbe9-3dc373edd45a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "TrainDataset, TrainLabelSet, TrainTabelSet = TrainDataGenerator(AnzahlAnTrainDaten)\n",
        "print(TrainDataset.shape)\n",
        "print(TrainTabelSet.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 64, 3)\n",
            "(10000, 32, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chkTMSVzn3k3",
        "colab_type": "text"
      },
      "source": [
        "# Mehrere Modelle und Ideen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vzgqkufSP5Y",
        "colab_type": "text"
      },
      "source": [
        "##Model 1 -> unverändert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kjoUg81bQMk",
        "colab_type": "code",
        "outputId": "364ace7e-84c4-4f51-ab24-4dc13eb7ddc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "input = keras.layers.Input((IMG_Height, IMG_Width, 3))\n",
        "\n",
        "model = tf.keras.applications.MobileNetV2()(input)\n",
        "CNN = keras.layers.Dense(IMG_Height*IMG_Width*4, activation='sigmoid')(model)\n",
        "\n",
        "for i in range(2,5):\n",
        "  CNN = tf.keras.layers.concatenate((CNN, model))\n",
        "  CNN = keras.layers.Dense(IMG_Height*IMG_Width*2, activation='sigmoid')(CNN)\n",
        "\n",
        "Zusammen = tf.keras.layers.concatenate((CNN, model))\n",
        "\n",
        "DNN = keras.layers.Dense(IMG_Height*IMG_Width*4, activation='softmax')(Zusammen)\n",
        "\n",
        "Output = keras.layers.Dense(IMG_Height*IMG_Width*3)(DNN)\n",
        "Output = keras.layers.Reshape(TrainTabelSet[0].shape)(Output)\n",
        "\n",
        "model = keras.models.Model(input, Output)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_2:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 64, 3).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFXBdRpra_Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.5)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbQhLfrFSTVg",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjZ8KY7Dumo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = myCallback()\n",
        "\n",
        "# history = model.fit(x = TrainDataset, y = TrainTabelSet, shuffle=True, epochs=10, validation_split=0.3, callbacks=[keras.callbacks.TerminateOnNaN()])     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZICxmZ98b4cO",
        "colab_type": "code",
        "outputId": "69936550-dbd6-4498-f4cb-87b602b74b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.plot(history.history['loss'], label = 'loss')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='center right')\n",
        "plt.show()\n",
        "\n",
        "TestDataSet, TestTabelSet, TestLabelSet = TestDataGenerator(AnzahlAnTestDaten)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(TestDataSet, TestTabelSet, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7bceff32175e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pQWt1xwSc8d",
        "colab_type": "text"
      },
      "source": [
        "###Auswertung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpe4wd4qV0l5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image, TrainLabelSet, tabel = TrainDataGenerator(1)\n",
        "\n",
        "print(image[0].shape)\n",
        "\n",
        "prediction = model.predict(image)\n",
        "\n",
        "plt.imshow(tabel[0])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(prediction[0])\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY2tIFMsSKsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwFHMolAnyMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZw9xcryoP5e",
        "colab_type": "text"
      },
      "source": [
        "# Model 2 -> weniger Schichten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNGrA6HFoYRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = keras.layers.Input((IMG_Height, IMG_Width, 3))\n",
        "\n",
        "model = tf.keras.applications.MobileNetV2()(input)\n",
        "CNN = keras.layers.Dense(IMG_Height*IMG_Width*4, activation='sigmoid')(model)\n",
        "\n",
        "for i in range(2,4):\n",
        "  CNN = tf.keras.layers.concatenate((CNN, model))\n",
        "  CNN = keras.layers.Dense(IMG_Height*IMG_Width*2, activation='sigmoid')(CNN)\n",
        "\n",
        "Zusammen = tf.keras.layers.concatenate((CNN, model))\n",
        "\n",
        "Output = keras.layers.Dense(IMG_Height*IMG_Width*3)(Zusammen)\n",
        "Output = keras.layers.Reshape(TrainTabelSet[0].shape)(Output)\n",
        "\n",
        "model = keras.models.Model(input, Output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eujjlMjfo3SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.5)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo5IdbNlo7GB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# history = model.fit(x = TrainDataset, y = TrainTabelSet, shuffle=True, epochs=10, validation_split=0.3, callbacks=[keras.callbacks.TerminateOnNaN()])     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyyGUMPvo-Gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.plot(history.history['loss'], label = 'loss')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='center right')\n",
        "plt.show()\n",
        "\n",
        "TestDataSet, TestTabelSet, TestLabelSet = TestDataGenerator(AnzahlAnTestDaten)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(TestDataSet, TestTabelSet, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq0biKpWo_sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image, TrainLabelSet, tabel = TrainDataGenerator(1)\n",
        "\n",
        "print(image[0].shape)\n",
        "\n",
        "prediction = model.predict(image)\n",
        "\n",
        "plt.imshow(tabel[0])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(prediction[0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtLiVYo_pZsR",
        "colab_type": "text"
      },
      "source": [
        "# Model 3 -> kleinere learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5Mo1RpPpket",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = keras.layers.Input((IMG_Height, IMG_Width, 3))\n",
        "\n",
        "model = tf.keras.applications.MobileNetV2()(input)\n",
        "CNN = keras.layers.Dense(IMG_Height*IMG_Width*4, activation='sigmoid')(model)\n",
        "\n",
        "for i in range(2,5):\n",
        "  CNN = tf.keras.layers.concatenate((CNN, model))\n",
        "  CNN = keras.layers.Dense(IMG_Height*IMG_Width*2, activation='sigmoid')(CNN)\n",
        "\n",
        "Zusammen = tf.keras.layers.concatenate((CNN, model))\n",
        "\n",
        "DNN = keras.layers.Dense(IMG_Height*IMG_Width*4, activation='softmax')(Zusammen)\n",
        "\n",
        "Output = keras.layers.Dense(IMG_Height*IMG_Width*3)(DNN)\n",
        "Output = keras.layers.Reshape(TrainTabelSet[0].shape)(Output)\n",
        "\n",
        "model = keras.models.Model(input, Output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5dMAp7GprCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.25)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=opt,\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI_5L1-kpwGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# history = model.fit(x = TrainDataset, y = TrainTabelSet, shuffle=True, epochs=20, validation_split=0.3, callbacks=[keras.callbacks.TerminateOnNaN()] )  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKxKfv_0pzAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "6f8ad151-7a8b-4908-d197-b5602673d699"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.plot(history.history['loss'], label = 'loss')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.3, 1])\n",
        "plt.legend(loc='center right')\n",
        "plt.show()\n",
        "\n",
        "TestDataSet, TestTabelSet, TestLabelSet = TestDataGenerator(AnzahlAnTestDaten)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(TestDataSet, TestTabelSet, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-688304cc8f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KHEjf7_qE5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image, TrainLabelSet, tabel = TrainDataGenerator(1)\n",
        "\n",
        "print(image[0].shape)\n",
        "\n",
        "prediction = model.predict(image)\n",
        "\n",
        "plt.imshow(tabel[0])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(prediction[0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwuwOUOBtIV6",
        "colab_type": "text"
      },
      "source": [
        "# Model 4 -> Kleineres Modell, kleinere Lernratte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifk2zB0LtOBi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b581d99f-4995-4ee4-f79a-6eac7eda9f7f"
      },
      "source": [
        "input = keras.layers.Input((IMG_Height, IMG_Width, 3))\n",
        "\n",
        "model = tf.keras.applications.MobileNetV2()(input)\n",
        "CNN = keras.layers.Dense(IMG_Height*IMG_Width*4, activation='sigmoid')(model)\n",
        "\n",
        "for i in range(2,4):\n",
        "  CNN = tf.keras.layers.concatenate((CNN, model))\n",
        "  CNN = keras.layers.Dense(IMG_Height*IMG_Width*2, activation='sigmoid')(CNN)\n",
        "\n",
        "Zusammen = tf.keras.layers.concatenate((CNN, model))\n",
        "\n",
        "Output = keras.layers.Dense(IMG_Height*IMG_Width*3)(Zusammen)\n",
        "Output = keras.layers.Reshape(TrainTabelSet[0].shape)(Output)\n",
        "\n",
        "model = keras.models.Model(input, Output)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_4:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 64, 3).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2IU-EVitUqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.25)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=opt,\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyzmyimStY6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "outputId": "ba7a0de4-ee02-404f-9652-f7c47428d671"
      },
      "source": [
        "history = model.fit(x = TrainDataset, y = TrainTabelSet, shuffle=True, epochs=30, validation_split=0.3, callbacks=[keras.callbacks.TerminateOnNaN()])  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_4:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 64, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_4:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 64, 3).\n",
            "219/219 [==============================] - ETA: 0s - loss: 2.6301 - accuracy: 0.3289WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_4:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 64, 3).\n",
            "219/219 [==============================] - 203s 929ms/step - loss: 2.6301 - accuracy: 0.3289 - val_loss: 2.6885 - val_accuracy: 0.3291\n",
            "Epoch 2/30\n",
            "219/219 [==============================] - 207s 947ms/step - loss: 2.6289 - accuracy: 0.3295 - val_loss: 2.6884 - val_accuracy: 0.3286\n",
            "Epoch 3/30\n",
            "219/219 [==============================] - 204s 933ms/step - loss: 2.6287 - accuracy: 0.3287 - val_loss: 2.6884 - val_accuracy: 0.3286\n",
            "Epoch 4/30\n",
            "219/219 [==============================] - 202s 921ms/step - loss: 2.6299 - accuracy: 0.3283 - val_loss: 2.6884 - val_accuracy: 0.3296\n",
            "Epoch 5/30\n",
            "219/219 [==============================] - 201s 917ms/step - loss: 2.6287 - accuracy: 0.3282 - val_loss: 2.6884 - val_accuracy: 0.3271\n",
            "Epoch 6/30\n",
            "219/219 [==============================] - 201s 918ms/step - loss: 2.6296 - accuracy: 0.3276 - val_loss: 2.6884 - val_accuracy: 0.3281\n",
            "Epoch 7/30\n",
            "219/219 [==============================] - 201s 918ms/step - loss: 2.6293 - accuracy: 0.3280 - val_loss: 2.6884 - val_accuracy: 0.3276\n",
            "Epoch 8/30\n",
            "219/219 [==============================] - 201s 917ms/step - loss: 2.6290 - accuracy: 0.3277 - val_loss: 2.6884 - val_accuracy: 0.3276\n",
            "Epoch 9/30\n",
            "219/219 [==============================] - 201s 917ms/step - loss: 2.6283 - accuracy: 0.3274 - val_loss: 2.6884 - val_accuracy: 0.3271\n",
            "Epoch 10/30\n",
            "219/219 [==============================] - 201s 920ms/step - loss: 2.6292 - accuracy: 0.3291 - val_loss: 2.6884 - val_accuracy: 0.3301\n",
            "Epoch 11/30\n",
            "219/219 [==============================] - 202s 922ms/step - loss: 2.6298 - accuracy: 0.3311 - val_loss: 2.6884 - val_accuracy: 0.3320\n",
            "Epoch 12/30\n",
            "219/219 [==============================] - 202s 920ms/step - loss: 2.6283 - accuracy: 0.3306 - val_loss: 2.6884 - val_accuracy: 0.3296\n",
            "Epoch 13/30\n",
            " 52/219 [======>.......................] - ETA: 2:23 - loss: 2.6451 - accuracy: 0.3293"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d75516e94dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainTabelSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTerminateOnNaN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    850\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjqtRwkataV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.plot(history.history['loss'], label = 'loss')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='center right')\n",
        "plt.show()\n",
        "\n",
        "TestDataSet, TestTabelSet, TestLabelSet = TestDataGenerator(AnzahlAnTestDaten)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(TestDataSet, TestTabelSet, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEQo6QKKtb58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image, TrainLabelSet, tabel = TrainDataGenerator(1)\n",
        "\n",
        "print(image[0].shape)\n",
        "\n",
        "prediction = model.predict(image)\n",
        "\n",
        "plt.imshow(tabel[0])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(prediction[0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppgNEwYwF59P",
        "colab_type": "text"
      },
      "source": [
        "# Test - Nur mit einem Bild rechnen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvsQO6fnGAQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "97e228ba-95db-4f81-e2c1-909b8fcd4b30"
      },
      "source": [
        "input = keras.layers.Input((IMG_Height, IMG_Width, 3))\n",
        "\n",
        "model = tf.keras.applications.MobileNetV2()(input)\n",
        "CNN = keras.layers.Dense(IMG_Height*IMG_Width*4, activation='sigmoid')(model)\n",
        "\n",
        "for i in range(2,5):\n",
        "  CNN = tf.keras.layers.concatenate((CNN, model))\n",
        "  CNN = keras.layers.Dense(IMG_Height*IMG_Width*2, activation='sigmoid')(CNN)\n",
        "\n",
        "Zusammen = tf.keras.layers.concatenate((CNN, model))\n",
        "\n",
        "DNN = keras.layers.Dense(IMG_Height*IMG_Width*4, activation='softmax')(Zusammen)\n",
        "\n",
        "Output = keras.layers.Dense(IMG_Height*IMG_Width*3)(DNN)\n",
        "Output = keras.layers.Reshape(TrainTabelSet[0].shape)(Output)\n",
        "\n",
        "model = keras.models.Model(input, Output)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_6:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 64, 3).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arhu3IV2GIdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPjGxJ8JGdKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_Height = 32\n",
        "IMG_Width = 64\n",
        "\n",
        "AnzahlAnTrainDaten = 1\n",
        "AnzahlAnTestDaten = 1\n",
        "DropoutRate = 0.5\n",
        "\n",
        "LossZumAbbruchDesTrainings = 0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYwcTF48GYsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d1b30ba5-5ddd-49c9-bff8-a8b5ef5b8fb6"
      },
      "source": [
        "TrainDataset, TrainLabelSet, TrainTabelSet = TrainDataGenerator(AnzahlAnTrainDaten)\n",
        "print(TrainDataset.shape)\n",
        "print(TrainTabelSet.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 32, 64, 3)\n",
            "(1, 32, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bITux_NdGLz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cec30de8-b1b1-4955-bc06-d52248308c3a"
      },
      "source": [
        "acc = []\n",
        "loss = []\n",
        "\n",
        "for i in range(0, 1000):\n",
        "  history = model.fit(x = TrainDataset, y = TrainTabelSet, shuffle=True, callbacks=[keras.callbacks.TerminateOnNaN()])\n",
        "  acc.append(history.history['accuracy'][0])\n",
        "  loss.append(history.history['loss'][0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0409 - accuracy: 0.3359\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1915 - accuracy: 0.3320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3605 - accuracy: 0.3350\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5364 - accuracy: 0.3359\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.6864 - accuracy: 0.3398\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7810 - accuracy: 0.3374\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.9116 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.9911 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1016 - accuracy: 0.3350\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1428 - accuracy: 0.3350\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.2395 - accuracy: 0.3345\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3048 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3552 - accuracy: 0.3379\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.4324 - accuracy: 0.3389\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.4755 - accuracy: 0.3394\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.5091 - accuracy: 0.3408\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.5819 - accuracy: 0.3403\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.5967 - accuracy: 0.3428\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6041 - accuracy: 0.3423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6306 - accuracy: 0.3423\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6363 - accuracy: 0.3413\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6902 - accuracy: 0.3384\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6765 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6819 - accuracy: 0.3364\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6860 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7378 - accuracy: 0.3364\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7577 - accuracy: 0.3354\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7660 - accuracy: 0.3354\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7719 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7864 - accuracy: 0.3359\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7910 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7860 - accuracy: 0.3345\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7708 - accuracy: 0.3340\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7849 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7781 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7761 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7857 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8127 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8241 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8264 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8297 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8267 - accuracy: 0.3286\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8476 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8620 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8811 - accuracy: 0.3276\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8971 - accuracy: 0.3262\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9165 - accuracy: 0.3276\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9156 - accuracy: 0.3271\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9190 - accuracy: 0.3276\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9263 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9315 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9265 - accuracy: 0.3286\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9379 - accuracy: 0.3271\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9563 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9555 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9785 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9781 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9748 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9784 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9778 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9775 - accuracy: 0.3286\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9772 - accuracy: 0.3286\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9770 - accuracy: 0.3276\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9769 - accuracy: 0.3267\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9767 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9765 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9763 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9763 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9842 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9842 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9841 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9920 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9998 - accuracy: 0.3281\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0031 - accuracy: 0.3281\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0007 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0004 - accuracy: 0.3296\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0003 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0001 - accuracy: 0.3286\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0079 - accuracy: 0.3281\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0078 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0077 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0076 - accuracy: 0.3320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0154 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0154 - accuracy: 0.3320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0232 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0231 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0230 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0230 - accuracy: 0.3320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0229 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0229 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0229 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3286\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3276\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3276\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3296\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3340\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0228 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3286\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3286\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0228 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3296\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3281\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3276\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3267\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3281\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3340\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3354\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3350\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3354\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3354\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0228 - accuracy: 0.3384\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3374\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3340\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0228 - accuracy: 0.3296\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3281\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3262\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3271\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3267\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3271\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3296\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3262\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3252\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3247\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3276\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3257\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3271\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3286\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3345\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3354\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3354\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3350\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3354\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3359\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3389\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3398\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3384\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3345\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3340\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3286\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3340\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3345\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3345\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3364\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3359\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3296\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3262\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3276\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3267\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3267\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3247\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3271\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3276\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3281\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3281\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3340\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0227 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3354\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3345\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3340\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3296\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3271\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3345\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3354\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3350\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3340\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0227 - accuracy: 0.3320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3296\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3359\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3345\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3340\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3354\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3350\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3374\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0227 - accuracy: 0.3389\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3394\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3384\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3389\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3364\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3389\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3384\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3359\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3345\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3350\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3379\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3364\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3374\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3379\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3384\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3379\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3403\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3433\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3442\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3472\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3462\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0227 - accuracy: 0.3467\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3457\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3438\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3438\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0226 - accuracy: 0.3457\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3472\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0226 - accuracy: 0.3477\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3477\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3457\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3438\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3467\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3472\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3452\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3477\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3467\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3481\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3481\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3467\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3467\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3477\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3481\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3481\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3477\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3481\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3481\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0226 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3477\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3467\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3481\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3481\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3481\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3477\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3481\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3481\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0226 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3496\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3511\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3506\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3521\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3579\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3579\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3584\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3579\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3579\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3579\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3535\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3540\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3579\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3550\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3574\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3579\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3555\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3564\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3569\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0225 - accuracy: 0.3560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcRIAW1mGPMQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "d3e63c41-79df-4466-e0cd-a6cea4eb554e"
      },
      "source": [
        "plt.plot(acc, label='accuracy')\n",
        "plt.plot(loss, label = 'loss')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: MatplotlibDeprecationWarning: Unrecognized location 'center down'. Falling back on 'best'; valid locations are\n",
            "\tbest\n",
            "\tupper right\n",
            "\tupper left\n",
            "\tlower left\n",
            "\tlower right\n",
            "\tright\n",
            "\tcenter left\n",
            "\tcenter right\n",
            "\tlower center\n",
            "\tupper center\n",
            "\tcenter\n",
            "This will raise an exception in 3.3.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}